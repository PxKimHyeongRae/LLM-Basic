# ì„œë²„ í•™ìŠµ ì‹¤í–‰ ê°€ì´ë“œ

## âœ… ë¡œì»¬ì—ì„œ ì™„ë£Œëœ ì‘ì—…

- [x] Claudeê°€ ì§ì ‘ 500ê°œ ì˜¨ë„ ë¹„êµ ë°ì´í„° ìƒì„±
- [x] DPO ë°ì´í„°ì…‹ 16ìŒ ìƒì„±
- [x] íŒŒì¼ ì €ì¥: `data/training_data_claude.jsonl`, `data/dpo_dataset.jsonl`

---

## ğŸ“¤ Step 1: ì„œë²„ë¡œ íŒŒì¼ ì „ì†¡

### Windowsì—ì„œ:

```bash
# SCP ì‚¬ìš© (PowerShell ë˜ëŠ” CMD)
cd C:\task\llm

scp data\training_data_claude.jsonl pluxity@ì„œë²„IP:~/lay/llm/data/
scp data\dpo_dataset.jsonl pluxity@ì„œë²„IP:~/lay/llm/data/
```

### ë˜ëŠ” WinSCP ì‚¬ìš©:
1. WinSCP ì‹¤í–‰
2. ì„œë²„ ì ‘ì†
3. ë¡œì»¬: `C:\task\llm\data\`
4. ì„œë²„: `~/lay/llm/data/`
5. ë‘ íŒŒì¼ ë“œë˜ê·¸ ì•¤ ë“œë¡­

---

## ğŸ“ Step 2: ì„œë²„ì—ì„œ DPO í•™ìŠµ ì‹¤í–‰

### 1. ì„œë²„ ì ‘ì†

```bash
ssh pluxity@ì„œë²„IP
cd ~/lay/llm
```

### 2. íŒŒì¼ í™•ì¸

```bash
ls -lh data/training_data_claude.jsonl
ls -lh data/dpo_dataset.jsonl

# ë¼ì¸ ìˆ˜ í™•ì¸
wc -l data/training_data_claude.jsonl  # 500ì¤„
wc -l data/dpo_dataset.jsonl           # 16ì¤„
```

### 3. Conda í™˜ê²½ í™œì„±í™”

```bash
conda activate ml
```

### 4. DPO í•™ìŠµ ì‹¤í–‰ (10-15ë¶„)

```bash
python scripts/finetune_dpo.py
```

**ì˜ˆìƒ ì†Œìš” ì‹œê°„**: 10-15ë¶„

**ì˜ˆìƒ ê²°ê³¼**:
```
ğŸš€ DPO í•™ìŠµ ì‹œì‘
...
âœ… DPO í•™ìŠµ ì™„ë£Œ! ëª¨ë¸ì´ ./finetuned_model_dpoì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.

ğŸ¯ íš¨ê³¼:
  - íŠ¹ìˆ˜ í† í° ìë™ ì œê±° í•™ìŠµ
  - ì§ˆë¬¸ í˜•ì‹ ìë™ ì œê±° í•™ìŠµ
  - ê°„ê²°í•˜ê³  ê¹”ë”í•œ ì¶œë ¥ í•™ìŠµ
  - Output cleaning ê·œì¹™ ë¶ˆí•„ìš”!
```

### 5. ëª¨ë¸ ì ìš©

```bash
# .env íŒŒì¼ ìˆ˜ì •
nano .env

# ë‹¤ìŒ ì¤„ ë³€ê²½:
# ADAPTER_PATH=./finetuned_model_dpo  ë¡œ ë³€ê²½
```

### 6. ëª¨ë¸ ì„œë²„ ì¬ì‹œì‘

```bash
# ê¸°ì¡´ ì„œë²„ ì¢…ë£Œ
pkill -f model_server.py

# ëª¨ë¸ ì„œë²„ ì¬ì‹œì‘
python model_server.py
```

---

## ğŸ§ª Step 3: í…ŒìŠ¤íŠ¸

### ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸:

```bash
# í…ŒìŠ¤íŠ¸ íŒŒì¼ ìˆë‹¤ë©´
python test_display_message.py
```

### ë˜ëŠ” Pythonìœ¼ë¡œ ì§ì ‘ í…ŒìŠ¤íŠ¸:

```python
import requests

# í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸
test_cases = [
    {"yesterday": 0, "today": 1},
    {"yesterday": -10, "today": 10},
    {"yesterday": 20, "today": 30},
]

for case in test_cases:
    prompt = f"ì–´ì œì˜ í‰ê· ì˜¨ë„ëŠ” {case['yesterday']}ë„ê³  ì˜¤ëŠ˜ì˜ í‰ê· ì˜¨ë„ëŠ” {case['today']}ë„ì•¼. " \
             f"ì´ëŸ° ê²½ìš°ì— ê³µì›ì„ ë°©ë¬¸í•˜ëŠ” ê³ ê°ë“¤ì—ê²Œ ì ì ˆí•˜ê²Œ ì „ë‹¬í•´ì¤„ ì „ê´‘íŒ ë©”ì‹œì§€ë¥¼ ì‘ì„±í•´ì¤˜"

    response = requests.post(
        "http://localhost:8000/generate",
        json={"prompt": prompt, "max_new_tokens": 100}
    )

    result = response.json()
    print(f"\nì…ë ¥: {case['yesterday']}ë„ â†’ {case['today']}ë„")
    print(f"ì¶œë ¥: {result['generated_text']}")
```

---

## ğŸ“Š ì˜ˆìƒ ê²°ê³¼

### Before (ê¸°ì¡´ íŒŒì¸íŠœë‹):
```
ì…ë ¥: 0ë„ â†’ 1ë„
ì¶œë ¥: .<think>...</think>
ì „ê´‘íŒì— í‘œì‹œí•  ë©”ì‹œì§€:
ì•ˆë…•í•˜ì„¸ìš”, ì˜¤ëŠ˜ ê³µì›ì€ ë” ì‹œì›í•©ë‹ˆë‹¤...
ì´ ë©”ì‹œì§€ê°€ ì ì ˆí•œê°€ìš”?
```

### After (DPO í•™ìŠµ):
```
ì…ë ¥: 0ë„ â†’ 1ë„
ì¶œë ¥: ì–´ì œë³´ë‹¤ 1ë„ ë”°ëœ»í•´ì¡ŒìŠµë‹ˆë‹¤. ì‚°ì±…í•˜ê¸° ì¢‹ì€ ë‚ ì”¨ì˜ˆìš”.
```

**íŠ¹ì§•**:
- âœ… íŠ¹ìˆ˜ í† í° ìë™ ì œê±°
- âœ… ì§ˆë¬¸ í˜•ì‹ ìë™ ì œê±°
- âœ… ê°„ê²°í•˜ê³  ê¹”ë” (40-70ì)
- âœ… ì˜¨ë„ ì°¨ì´ ëª…ì‹œ
- âœ… ê·œì¹™ ì—†ì´ ëª¨ë¸ì´ í•™ìŠµ!

---

## ğŸ†˜ ë¬¸ì œ í•´ê²°

### CUDA OOM ì—ëŸ¬:

```python
# scripts/finetune_dpo.py ìˆ˜ì •
gradient_accumulation_steps=8  # 4 â†’ 8ë¡œ ì¦ê°€
per_device_train_batch_size=1  # ìœ ì§€
```

### "Module 'trl' has no DPOTrainer":

```bash
pip install --upgrade trl
```

### DPO í•™ìŠµì´ ë„ˆë¬´ ì˜¤ë˜ ê±¸ë¦¼:

```python
# scripts/finetune_dpo.py ìˆ˜ì •
num_train_epochs=2  # 3 â†’ 2ë¡œ ê°ì†Œ
```

---

## ğŸ“ˆ ì„±ëŠ¥ ë¹„êµ

### ê¸°ì¡´ (401ê°œ ê·œì¹™ ê¸°ë°˜ ë°ì´í„°):
- ì†ì‹¤ ê°œì„ : 94.6% (3.43 â†’ 0.18)
- ë¬¸ì œ: íŠ¹ìˆ˜ í† í°, ì§ˆë¬¸, ì¥í™©í•¨

### Phase 0 (500ê°œ Claude ë°ì´í„° + DPO):
- **ì˜ˆìƒ ì†ì‹¤ ê°œì„ **: 95%+
- **ì˜ˆìƒ íš¨ê³¼**:
  - íŠ¹ìˆ˜ í† í° ì œê±° í•™ìŠµ
  - ì§ˆë¬¸ í˜•ì‹ ì œê±° í•™ìŠµ
  - ê°„ê²°ì„± í•™ìŠµ
  - ì˜¨ë„ ì°¨ì´ ëª…ì‹œ í•™ìŠµ

---

## âœ… ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì „ì†¡ ì „:
- [ ] `data/training_data_claude.jsonl` ì¡´ì¬ (500ì¤„)
- [ ] `data/dpo_dataset.jsonl` ì¡´ì¬ (16ì¤„)

### ì„œë²„ì—ì„œ:
- [ ] íŒŒì¼ ì „ì†¡ í™•ì¸
- [ ] DPO í•™ìŠµ ì‹¤í–‰
- [ ] `finetuned_model_dpo/` ìƒì„± í™•ì¸
- [ ] .env ìˆ˜ì • (ADAPTER_PATH)
- [ ] ëª¨ë¸ ì„œë²„ ì¬ì‹œì‘
- [ ] í…ŒìŠ¤íŠ¸ ì‹¤í–‰

---

## ğŸ’¡ ì™„ë£Œ í›„

í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ê³µìœ í•´ì£¼ì„¸ìš”!

**ê³µìœ í•  ë‚´ìš©**:
- í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ 3-5ê°œ
- ê°ê°ì˜ ì¶œë ¥ ê²°ê³¼
- ê°œì„ ë˜ì—ˆëŠ”ì§€ ì—¬ë¶€

---

> ğŸ¯ **Phase 0 í•µì‹¬**: ê·œì¹™ì„ ì§œì§€ ë§ê³ , ëª¨ë¸ì´ í•™ìŠµí•˜ê²Œ í•˜ì!
