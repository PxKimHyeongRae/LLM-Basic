"""
í•©ì„± í•™ìŠµ ë°ì´í„° ìƒì„± ìŠ¤í¬ë¦½íŠ¸
OpenRouter APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì „ê´‘íŒ ë©”ì‹œì§€ í•™ìŠµ ë°ì´í„°ë¥¼ ìë™ ìƒì„±í•©ë‹ˆë‹¤.
"""

import os
import json
import random
from typing import List, Dict
from openai import OpenAI
from dotenv import load_dotenv
from tqdm import tqdm

load_dotenv()

# OpenRouter í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
client = OpenAI(
    base_url="https://openrouter.ai/api/v1",
    api_key=os.getenv('OPENROUTER_API_KEY'),
)

def generate_message_pair(scenario: str, context: Dict) -> Dict:
    """
    ì£¼ì–´ì§„ ì‹œë‚˜ë¦¬ì˜¤ì™€ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì…ë ¥-ì¶œë ¥ ìŒì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    prompt = f"""ë‹¹ì‹ ì€ ì•¼ì™¸ ê³µì› ì „ê´‘íŒ ë©”ì‹œì§€ ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì‹œë‚˜ë¦¬ì˜¤: {scenario}
ì»¨í…ìŠ¤íŠ¸: {json.dumps(context, ensure_ascii=False)}

ìœ„ ì‹œë‚˜ë¦¬ì˜¤ì— ëŒ€í•´ ë‹¤ìŒì„ ìƒì„±í•˜ì„¸ìš”:
1. ì‚¬ìš©ì ì…ë ¥ (input): ê°„ë‹¨í•œ ë©”ëª¨ë‚˜ ì„¼ì„œ ë°ì´í„° ì„¤ëª… (10-30ì)
2. ì „ê´‘íŒ ì¶œë ¥ (output): ê³µì› ì‹œë¯¼ë“¤ì—ê²Œ ë³´ë‚¼ ì¹œê·¼í•˜ê³  ëª…í™•í•œ ì•ˆë‚´ ë©”ì‹œì§€ (40-70ì)

ê·œì¹™:
- ì¡´ëŒ“ë§ ì‚¬ìš© (ï½ìš”, ï½ì„¸ìš”)
- ê³µê³µì˜ ì´ìµì„ ìœ„í•œ ë‚´ìš©
- êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸
- ë¶€ì •ì  í‘œí˜„ë³´ë‹¤ëŠ” ê¸ì •ì  ì œì•ˆ

JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”:
{{"input": "...", "output": "..."}}
"""

    try:
        completion = client.chat.completions.create(
            extra_body={},
            model=os.getenv('OPENROUTER_MODEL', 'tngtech/deepseek-r1t2-chimera:free'),
            messages=[{"role": "user", "content": prompt}]
        )

        response_text = completion.choices[0].message.content.strip()

        # JSON ì¶”ì¶œ (ì½”ë“œ ë¸”ë¡ ì œê±°)
        if "```json" in response_text:
            response_text = response_text.split("```json")[1].split("```")[0].strip()
        elif "```" in response_text:
            response_text = response_text.split("```")[1].split("```")[0].strip()

        data = json.loads(response_text)
        return data

    except Exception as e:
        print(f"Error generating pair: {e}")
        return None


def create_scenarios() -> List[tuple]:
    """
    ë‹¤ì–‘í•œ ì‹œë‚˜ë¦¬ì˜¤ì™€ ì»¨í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    """
    scenarios = []

    # 1. ì˜¨ë„ ê¸°ë°˜ ì‹œë‚˜ë¦¬ì˜¤ (30ê°œ)
    temperatures = [
        (35, 45, "í­ì—¼"), (30, 40, "ë”ìœ„"), (25, 30, "ë”°ëœ»í•¨"),
        (20, 25, "ì¾Œì í•¨"), (15, 20, "ì„ ì„ í•¨"), (10, 15, "ìŒ€ìŒ€í•¨"),
        (5, 10, "ì¶”ìœ„"), (0, 5, "ê°•ì¶”ìœ„"), (-5, 0, "í˜¹í•œ")
    ]

    for temp_min, temp_max, condition in temperatures:
        for i in range(3):
            temp = random.randint(temp_min, temp_max)
            scenarios.append((
                f"ì˜¨ë„ {temp}Â°C - {condition} ìƒí™©",
                {"temperature": temp, "condition": condition, "location": "ê³µì›"}
            ))

    # 2. ìŠµë„ ê¸°ë°˜ ì‹œë‚˜ë¦¬ì˜¤ (20ê°œ)
    humidity_ranges = [
        (80, 95, "ë§¤ìš° ìŠµí•¨"), (70, 80, "ìŠµí•¨"),
        (40, 60, "ì¾Œì "), (20, 40, "ê±´ì¡°"), (10, 20, "ë§¤ìš° ê±´ì¡°")
    ]

    for hum_min, hum_max, condition in humidity_ranges:
        for i in range(4):
            humidity = random.randint(hum_min, hum_max)
            scenarios.append((
                f"ìŠµë„ {humidity}% - {condition} ìƒí™©",
                {"humidity": humidity, "condition": condition, "location": "ê³µì›"}
            ))

    # 3. ì˜¨ë„+ìŠµë„ ë³µí•© ì‹œë‚˜ë¦¬ì˜¤ (20ê°œ)
    combined_scenarios = [
        (32, 75, "ë¬´ë”ìœ„"), (28, 85, "ì°œí†µë”ìœ„"), (5, 80, "ìŠµí•œ ì¶”ìœ„"),
        (15, 30, "ê±´ì¡°í•œ ë‚ ì”¨"), (-2, 60, "í•œíŒŒ")
    ]

    for temp, humidity, condition in combined_scenarios:
        for i in range(4):
            scenarios.append((
                f"ì˜¨ë„ {temp}Â°C, ìŠµë„ {humidity}% - {condition}",
                {"temperature": temp, "humidity": humidity, "condition": condition}
            ))

    # 4. ë³€ìœ„ê³„ ì´ìƒ ì‹œë‚˜ë¦¬ì˜¤ (15ê°œ)
    displacement_scenarios = [
        "Xì¶• ê°ë„ ì´ìƒ ê°ì§€", "Yì¶• ê°ë„ ì´ìƒ ê°ì§€", "ë³€ìœ„ê³„ ê¸°ìš¸ê¸° ê°ì§€",
        "ì‹œì„¤ë¬¼ ì ê²€ í•„ìš”", "êµ¬ì¡°ë¬¼ ëª¨ë‹ˆí„°ë§ ì¤‘"
    ]

    for scenario in displacement_scenarios:
        for i in range(3):
            x_angle = random.uniform(-5, 5)
            y_angle = random.uniform(-5, 5)
            scenarios.append((
                scenario,
                {"x_angle": round(x_angle, 2), "y_angle": round(y_angle, 2),
                 "alert_type": "ì•ˆì „ì ê²€"}
            ))

    # 5. ì¼ë°˜ ê³µì› ì•ˆë‚´ ì‹œë‚˜ë¦¬ì˜¤ (30ê°œ)
    general_scenarios = [
        ("ì“°ë ˆê¸° ë¶„ë¦¬ìˆ˜ê±° ì•ˆë‚´", {"category": "í™˜ê²½"}),
        ("ë°˜ë ¤ë™ë¬¼ ë™ë°˜ ì•ˆë‚´", {"category": "ì´ìš©ìˆ˜ì¹™"}),
        ("í¡ì—° êµ¬ì—­ ì•ˆë‚´", {"category": "ì´ìš©ìˆ˜ì¹™"}),
        ("ìš´ë™ê¸°êµ¬ ì´ìš© ì•ˆë‚´", {"category": "ì‹œì„¤"}),
        ("í™”ì¥ì‹¤ ìœ„ì¹˜ ì•ˆë‚´", {"category": "í¸ì˜ì‹œì„¤"}),
        ("ìŒìˆ˜ëŒ€ ì´ìš© ì•ˆë‚´", {"category": "í¸ì˜ì‹œì„¤"}),
        ("ì•¼ê°„ ìš´ì˜ì‹œê°„ ì•ˆë‚´", {"category": "ìš´ì˜"}),
        ("ìš°ì²œ ì‹œ ì£¼ì˜ì‚¬í•­", {"category": "ì•ˆì „"}),
        ("ë¯¸ë„ëŸ¼ ì£¼ì˜", {"category": "ì•ˆì „"}),
        ("ë‚™ìƒ ì£¼ì˜", {"category": "ì•ˆì „"}),
    ]

    for scenario, context in general_scenarios:
        for i in range(3):
            scenarios.append((scenario, context))

    # 6. ê³„ì ˆë³„ íŠ¹í™” ì‹œë‚˜ë¦¬ì˜¤ (20ê°œ)
    seasonal_scenarios = [
        ("ë´„ì²  í™©ì‚¬ ì£¼ì˜", {"season": "ë´„", "issue": "í™©ì‚¬"}),
        ("ì—¬ë¦„ í­ì—¼ ëŒ€ë¹„", {"season": "ì—¬ë¦„", "issue": "í­ì—¼"}),
        ("ê°€ì„ ë‚™ì—½ ì²­ì†Œ", {"season": "ê°€ì„", "issue": "í™˜ê²½"}),
        ("ê²¨ìš¸ ë¹™íŒ ì£¼ì˜", {"season": "ê²¨ìš¸", "issue": "ì•ˆì „"}),
        ("ì¥ë§ˆì²  ëŒ€ë¹„", {"season": "ì—¬ë¦„", "issue": "ê°•ìˆ˜"}),
    ]

    for scenario, context in seasonal_scenarios:
        for i in range(4):
            scenarios.append((scenario, context))

    # 7. ê¸´ê¸‰/ì¬ë‚œ ì•ˆë‚´ ì‹œë‚˜ë¦¬ì˜¤ (15ê°œ)
    emergency_scenarios = [
        ("ë¯¸ì„¸ë¨¼ì§€ ë‚˜ì¨", {"pm10": 120, "level": "ë‚˜ì¨"}),
        ("ì´ˆë¯¸ì„¸ë¨¼ì§€ ë§¤ìš°ë‚˜ì¨", {"pm2.5": 80, "level": "ë§¤ìš°ë‚˜ì¨"}),
        ("ì˜¤ì¡´ ê²½ë³´", {"o3": 0.15, "level": "ê²½ë³´"}),
        ("í­ì—¼ ê²½ë³´", {"temperature": 38, "level": "ê²½ë³´"}),
        ("í•œíŒŒ ì£¼ì˜ë³´", {"temperature": -10, "level": "ì£¼ì˜ë³´"}),
    ]

    for scenario, context in emergency_scenarios:
        for i in range(3):
            scenarios.append((scenario, context))

    return scenarios


def generate_dataset(num_samples: int = 150, output_file: str = "data/training_data.jsonl"):
    """
    í•™ìŠµ ë°ì´í„°ì…‹ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    print(f"ì´ {num_samples}ê°œì˜ í•™ìŠµ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")

    # ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±
    all_scenarios = create_scenarios()

    # ëœë¤í•˜ê²Œ ì„ê¸°
    random.shuffle(all_scenarios)

    # í•„ìš”í•œ ë§Œí¼ë§Œ ì„ íƒ
    selected_scenarios = all_scenarios[:num_samples]

    # ë°ì´í„° ìƒì„±
    dataset = []

    for scenario, context in tqdm(selected_scenarios, desc="ë°ì´í„° ìƒì„± ì¤‘"):
        pair = generate_message_pair(scenario, context)

        if pair and "input" in pair and "output" in pair:
            dataset.append(pair)
        else:
            print(f"ì‹¤íŒ¨í•œ ì‹œë‚˜ë¦¬ì˜¤: {scenario}")

    # íŒŒì¼ ì €ì¥
    os.makedirs(os.path.dirname(output_file), exist_ok=True)

    with open(output_file, 'w', encoding='utf-8') as f:
        for item in dataset:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')

    print(f"\nâœ… {len(dataset)}ê°œì˜ ë°ì´í„°ê°€ {output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # ìƒ˜í”Œ ì¶œë ¥
    print("\nğŸ“‹ ìƒì„±ëœ ë°ì´í„° ìƒ˜í”Œ:")
    for i, item in enumerate(dataset[:5], 1):
        print(f"\n{i}.")
        print(f"  ì…ë ¥: {item['input']}")
        print(f"  ì¶œë ¥: {item['output']}")


def split_dataset(input_file: str = "data/training_data.jsonl",
                  train_ratio: float = 0.9):
    """
    ë°ì´í„°ì…‹ì„ í•™ìŠµ/ê²€ì¦ ì„¸íŠ¸ë¡œ ë¶„í• í•©ë‹ˆë‹¤.
    """
    with open(input_file, 'r', encoding='utf-8') as f:
        data = [json.loads(line) for line in f]

    random.shuffle(data)

    split_idx = int(len(data) * train_ratio)
    train_data = data[:split_idx]
    val_data = data[split_idx:]

    # ì €ì¥
    with open('data/train.jsonl', 'w', encoding='utf-8') as f:
        for item in train_data:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')

    with open('data/validation.jsonl', 'w', encoding='utf-8') as f:
        for item in val_data:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')

    print(f"\nâœ… ë°ì´í„° ë¶„í•  ì™„ë£Œ:")
    print(f"  - í•™ìŠµ ë°ì´í„°: {len(train_data)}ê°œ â†’ data/train.jsonl")
    print(f"  - ê²€ì¦ ë°ì´í„°: {len(val_data)}ê°œ â†’ data/validation.jsonl")


if __name__ == "__main__":
    # 1. í•™ìŠµ ë°ì´í„° ìƒì„± (150ê°œ)
    generate_dataset(num_samples=150)

    # 2. í•™ìŠµ/ê²€ì¦ ë¶„í• 
    split_dataset()
